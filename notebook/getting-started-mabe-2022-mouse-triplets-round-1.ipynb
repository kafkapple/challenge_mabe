{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNzVqbnxvTRS"
      },
      "source": [
        "![Problem Statement](https://images.aicrowd.com/uploads/ckeditor/pictures/711/content_embedding_problem_statement.png)\n",
        "\n",
        "\n",
        "\n",
        "<p align=\"center\"> Join the communty! <br><a href=\"https://discord.gg/GTckBMx\"><img src=\"https://img.shields.io/discord/657211973435392011?style=for-the-badge\" alt=\"chat on Discord\"></a>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ad-nu4cbF_fI"
      },
      "source": [
        "# How to use this notebook üìù\n",
        "\n",
        "1. **Copy the notebook**. This is a shared template and any edits you make here will not be saved. _You should copy it into your own drive folder._ For this, click the \"File\" menu (top-left), then \"Save a Copy in Drive\". You can edit your copy however you like.\n",
        "2. **Link it to your AIcrowd account**. In order to submit your predictions to AIcrowd, you need to provide your account's API key.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOsJQCoRvTRY"
      },
      "source": [
        "# Setup AIcrowd Utilities üõ†"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCKS_X_KvTRY"
      },
      "outputs": [],
      "source": [
        "!pip install -U aicrowd-cli\n",
        "%load_ext aicrowd.magic"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqraoVVX4EBb"
      },
      "source": [
        "\n",
        "## Login to AIcrowd „äó¬∂\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9TkEMV3g3_XV"
      },
      "outputs": [],
      "source": [
        "%aicrowd login"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuQQrNvkID8J"
      },
      "source": [
        "# Install packages üóÉ\n",
        "\n",
        "Please add all pacakages installations in this section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPsQS64kIFIz"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsaWsU8dILfN"
      },
      "source": [
        "# Import necessary modules and packages üìö\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G4CVVoCjIN95"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KwykJ9kzvTRZ"
      },
      "source": [
        "# Download the dataset üì≤\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwZgcLsNDej_"
      },
      "outputs": [],
      "source": [
        "aicrowd_challenge_name = \"mabe-2022-mouse-triplets\"\n",
        "if not os.path.exists('data'):\n",
        "  os.mkdir('data')\n",
        "\n",
        "# %aicrowd ds dl -c {aicrowd_challenge_name} -o data # Download all files\n",
        "%aicrowd ds dl -c {aicrowd_challenge_name} -o data *submission_data* # download only the submission keypoint data\n",
        "%aicrowd ds dl -c {aicrowd_challenge_name} -o data *user_train* # download data with the public task labels provided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xxx3o-TP70Pn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MLxouZUvTRa"
      },
      "source": [
        "# Load Data\n",
        "The dataset files are python dictionaries, [this](https://colab.research.google.com/drive/1ddCX-TAdEcsUaGf09f5Glgr_G57FMK_O#scrollTo=JPsfxdl2GMcM&line=18&uniqifier=1) is a descirption of how the data is organized.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RopVoFl1vTRb"
      },
      "outputs": [],
      "source": [
        "submission_clips = np.load('data/submission_data.npy',allow_pickle=True).item()\n",
        "user_train = np.load('data/user_train.npy',allow_pickle=True).item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFcS9p3haBkK"
      },
      "source": [
        "## Dataset Specifications üíæ\n",
        "\n",
        "We provide frame-by-frame animal pose estimates extracted from top-view videos of trios of interacting mice filmed at 30Hz; raw videos will not be provided for this stage of the competition. Animal poses are characterized by the tracked locations of body parts on each animal, termed \"keypoints.\"\n",
        "\n",
        "The following files are available in the `resources` section. A \"sequence\" is a continuous recording of social interactions between animals: sequences are 1 minute long (1800 frames at 30Hz) in the mouse dataset. The `sequence_id` is a random hash to anonymize experiment details.\n",
        "\n",
        "\n",
        "- `user_train.npy` - Training set for the task, which follows the following schema :\n",
        "\n",
        "```\n",
        "{\n",
        "    \"sequences\" : {\n",
        "        \"<sequence_id> : {\n",
        "            \"keypoints\" : a ndarray of shape (4500, 11, 24, 2)\n",
        "        }\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n",
        "- `submission_clips.npy` - Test set for the task, which follows the following schema:\n",
        "\n",
        "```\n",
        "{\n",
        "    \"<sequence_id> : {\n",
        "        \"keypoints\" : a ndarray of shape (4500, 11, 24, 2)\n",
        "    }\n",
        "}\n",
        "```\n",
        "- sample_submission.npy - Template for a sample submission for this task, follows the following schema :\n",
        "\n",
        "```\n",
        "{\n",
        "    \"frame_number_map\": \n",
        "        {\"<sequence_id-1>\": (start_frame_index, end_frame_index),\n",
        "        \"<sequence_id-1>\": (start_frame_index, end_frame_index),\n",
        "        ...\n",
        "        \"<sequence_id-n>\": (start_frame_index, end_frame_index),\n",
        "        }\n",
        "    \"<sequence_id-1>\" : [\n",
        "            [0.321, 0.234, 0.186, 0.857, 0.482, 0.185], .....]\n",
        "            [0.184, 0.583, 0.475], 0.485, 0.275, 0.958], .....]\n",
        "        ]\n",
        "}\n",
        "```\n",
        "\n",
        "In `sample_submission`, each key in the `frame_number_map` dictionary refers to the unique sequence id of a video in the test set. The item for each key is expected to be an the start and end index for slicing the `embeddings` numpy array to get the corresponding embeddings. The `embeddings` array is a 2D `ndarray` of floats of size `total_frames` by `X` , where `X` is the dimension of your learned embedding (6 in the above example; maximum permitted embedding dimension is **128**), representing the embedded value of each frame in the sequence. `total_frames` is the sum of all the frames of the sequences, the array should be concatenation of all the embeddings of all the clips.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUkb35tcf4bn"
      },
      "source": [
        "## How does the data look like? üîç"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CYIC5DW_oRPb"
      },
      "outputs": [],
      "source": [
        "print(\"Dataset keys - \", submission_clips.keys())\n",
        "print(\"Number of submission sequences - \", len(submission_clips['sequences']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luUly4Y1i4L-"
      },
      "source": [
        "### Sample overview"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hh9dj4wG3rV0"
      },
      "outputs": [],
      "source": [
        "sequence_names = list(submission_clips[\"sequences\"].keys())\n",
        "sequence_key = sequence_names[0]\n",
        "single_sequence = submission_clips[\"sequences\"][sequence_key][\"keypoints\"]\n",
        "print(\"Sequence name - \", sequence_key\n",
        "print(\"Single Sequence shape \", single_sequence.shape)\n",
        "print(f\"Number of Frames in {sequence_key} - \", len(single_sequence))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUT-lp7ByRxe"
      },
      "source": [
        "Keypoints are stored in an ndarray with the following properties:\n",
        "\n",
        "- Dimensions: (`# frames`) x (`animal ID`) x (`body part`) x (`x, y coordinate`).\n",
        "- Units: pixels; coordinates are relative to the entire image. Original image dimensions are **850 x 850** for the mouse dataset.\n",
        "\n",
        "Body parts are ordered: **1) nose, 2) left ear, 3) right ear, 4) neck, 5) left forepaw, 6) right forepaw, 7) center back, 8) left hindpaw, 9) right hindpaw, 10) tail base, 11) tail middle, 12) tail tip**.\n",
        "\n",
        "The placement of these keypoints is illustrated below:\n",
        "![diagram of keypoint locations](https://images.aicrowd.com/uploads/ckeditor/pictures/702/content_keypoint_ids_mouse.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_WGK1pjV81oc"
      },
      "source": [
        "# Helper function for visualization üíÅ\n",
        "\n",
        "Useful functions for interacting with the mouse tracking sequences\n",
        "\n",
        "\n",
        "Don't forget to run the cell üòâ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HgU5Ye6EyiBh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from matplotlib import colors\n",
        "from matplotlib import rc\n",
        "\n",
        "rc('animation', html='jshtml')\n",
        " \n",
        "# Note: Image processing may be slow if too many frames are animated.                \n",
        " \n",
        "#Plotting constants\n",
        "FRAME_WIDTH_TOP = 850\n",
        "FRAME_HEIGHT_TOP = 850\n",
        " \n",
        "M1_COLOR = 'lawngreen'\n",
        "M2_COLOR = 'skyblue'\n",
        "M3_COLOR = 'tomato'\n",
        " \n",
        "PLOT_MOUSE_START_END = [(0, 1), (1, 3), (3, 2), (2, 0),        # head\n",
        "                        (3, 6), (6, 9),                        # midline\n",
        "                        (9, 10), (10, 11),                     # tail\n",
        "                        (4, 5), (5, 8), (8, 9), (9, 7), (7, 4) # legs\n",
        "                       ]\n",
        " \n",
        "class_to_number = {s: i for i, s in enumerate(user_train['vocabulary'])}\n",
        " \n",
        "number_to_class = {i: s for i, s in enumerate(user_train['vocabulary'])}\n",
        " \n",
        "def num_to_text(anno_list):\n",
        "  return np.vectorize(number_to_class.get)(anno_list)\n",
        " \n",
        "def set_figax():\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        " \n",
        "    img = np.zeros((FRAME_HEIGHT_TOP, FRAME_WIDTH_TOP, 3))\n",
        " \n",
        "    ax = fig.add_subplot(111)\n",
        "    ax.imshow(img)\n",
        " \n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        " \n",
        "    return fig, ax\n",
        " \n",
        "def plot_mouse(ax, pose, color):\n",
        "    # Draw each keypoint\n",
        "    for j in range(10):\n",
        "        ax.plot(pose[j, 0], pose[j, 1], 'o', color=color, markersize=3)\n",
        " \n",
        "    # Draw a line for each point pair to form the shape of the mouse\n",
        " \n",
        "    for pair in PLOT_MOUSE_START_END:\n",
        "        line_to_plot = pose[pair, :]\n",
        "        ax.plot(line_to_plot[:, 0], line_to_plot[\n",
        "                :, 1], color=color, linewidth=1)\n",
        " \n",
        "def animate_pose_sequence(video_name, seq, start_frame = 0, stop_frame = 100, skip = 0,\n",
        "                          annotation_sequence = None):\n",
        "    # Returns the animation of the keypoint sequence between start frame\n",
        "    # and stop frame. Optionally can display annotations.\n",
        " \n",
        "    image_list = []\n",
        "    \n",
        "    counter = 0\n",
        "    if skip:\n",
        "        anim_range = range(start_frame, stop_frame, skip)\n",
        "    else:\n",
        "        anim_range = range(start_frame, stop_frame)\n",
        "    \n",
        "    for j in anim_range:\n",
        "        if counter%20 == 0:\n",
        "          print(\"Processing frame \", j)\n",
        "        fig, ax = set_figax()\n",
        "        plot_mouse(ax, seq[j, 0, :, :], color=M1_COLOR)\n",
        "        plot_mouse(ax, seq[j, 1, :, :], color=M2_COLOR)\n",
        "        plot_mouse(ax, seq[j, 2, :, :], color=M3_COLOR)\n",
        "        \n",
        "        if annotation_sequence is not None:\n",
        "          annot = annotation_sequence[j]\n",
        "          annot = number_to_class[annot]\n",
        "          plt.text(50, -20, annot, fontsize = 16, \n",
        "                   bbox=dict(facecolor=class_to_color[annot], alpha=0.5))\n",
        " \n",
        "        ax.set_title(\n",
        "            video_name + '\\n frame {:03d}.png'.format(j))\n",
        " \n",
        "        ax.axis('off')\n",
        "        fig.tight_layout(pad=0)\n",
        "        ax.margins(0)\n",
        " \n",
        "        fig.canvas.draw()\n",
        "        image_from_plot = np.frombuffer(fig.canvas.tostring_rgb(),\n",
        "                                        dtype=np.uint8)\n",
        "        image_from_plot = image_from_plot.reshape(\n",
        "            fig.canvas.get_width_height()[::-1] + (3,)) \n",
        " \n",
        "        image_list.append(image_from_plot)\n",
        " \n",
        "        plt.close()\n",
        "        counter = counter + 1\n",
        " \n",
        "    # Plot animation.\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    plt.axis('off')\n",
        "    im = plt.imshow(image_list[0])\n",
        " \n",
        "    def animate(k):\n",
        "        im.set_array(image_list[k])\n",
        "        return im,\n",
        "    ani = animation.FuncAnimation(fig, animate, frames=len(image_list), blit=True)\n",
        "    return ani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7WPezuV86QA"
      },
      "source": [
        "# Visualize the mouse movementsüé•\n",
        "\n",
        "Sample visualization for plotting pose gifs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fxzXnJEzWk-"
      },
      "outputs": [],
      "source": [
        "sequence_names = list(user_train['sequences'].keys())\n",
        "sequence_key = sequence_names[0]\n",
        "single_sequence = user_train[\"sequences\"][sequence_key]\n",
        "\n",
        "\n",
        "keypoint_sequence = single_sequence['keypoints']\n",
        "filled_sequence = fill_holes(keypoint_sequence)\n",
        "masked_data = np.ma.masked_where(keypoint_sequence==0, keypoint_sequence)\n",
        "\n",
        "annotation_sequence = None  # single_sequence['annotations']\n",
        "\n",
        "ani = animate_pose_sequence(sequence_key,\n",
        "                            filled_sequence, \n",
        "                            start_frame = 0,\n",
        "                            stop_frame = 1800,\n",
        "                            skip = 10,\n",
        "                            annotation_sequence = annotation_sequence)\n",
        "\n",
        "# Display the animaion on colab\n",
        "ani"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCDiH6VCZ_EB"
      },
      "source": [
        "# Simple Embedding : Framewise PCA \n",
        "\n",
        "Each frame contains tracking of multiple mice, in this simple submission, we'll do Principal component analysis of every frame. These PCA embeddings will be used as our submission. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iKG5MfYIu1B"
      },
      "source": [
        "## Seeding helper\n",
        "Its good practice to seed before every run, that way its easily reproduced."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r4rNTUuFaHmo"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "  np.random.seed(seed)\n",
        "  os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "seed=42\n",
        "seed_everything(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kV_lRQwH8Xxi"
      },
      "source": [
        "## Extract PCA per frame\n",
        "\n",
        "First, we'll make a helper function to interpolate missing keypoint locations (identified as entries where the keypoint location is 0.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NfrGG5hrLwB2"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "def fill_holes(data):\n",
        "    clean_data = copy.deepcopy(data)\n",
        "    for m in range(3):\n",
        "        holes = np.where(clean_data[0,m,:,0]==0)\n",
        "        if not holes:\n",
        "            continue\n",
        "        for h in holes[0]:\n",
        "            sub = np.where(clean_data[:,m,h,0]!=0)\n",
        "            if(sub and sub[0].size > 0):\n",
        "                clean_data[0,m,h,:] = clean_data[sub[0][0],m,h,:]\n",
        "            else:\n",
        "              return np.empty((0))\n",
        "    \n",
        "    for fr in range(1,np.shape(clean_data)[0]):\n",
        "        for m in range(3):\n",
        "            holes = np.where(clean_data[fr,m,:,0]==0)\n",
        "            if not holes:\n",
        "                continue\n",
        "            for h in holes[0]:\n",
        "                clean_data[fr,m,h,:] = clean_data[fr-1,m,h,:]\n",
        "    return clean_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEeAaIAKYcMf"
      },
      "source": [
        "Next we'll stack up all of the training sequences to create the data we'll use to fit our principal axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rz1_tGnvZVP3"
      },
      "outputs": [],
      "source": [
        "# generate the training data for PCA by stacking the entries of user_train\n",
        "sequence_keys = list(user_train['sequences'].keys())\n",
        "num_total_frames = np.sum([seq[\"keypoints\"].shape[0] for _, seq in submission_clips['sequences'].items()])\n",
        "sequence_dim = np.shape(user_train['sequences'][sequence_keys[0]]['keypoints'])\n",
        "keypoints_dim = sequence_dim[1]*sequence_dim[2]*sequence_dim[3]\n",
        "\n",
        "pca_train = np.empty((num_total_frames, keypoints_dim, 3), dtype=np.float32)\n",
        "start = 0\n",
        "for k in sequence_keys:\n",
        "  keypoints = fill_holes(user_train['sequences'][k][\"keypoints\"])\n",
        "  if keypoints.size == 0:  # sometimes a mouse is missing the entire time\n",
        "    continue\n",
        "\n",
        "  end = start + len(keypoints)\n",
        "  for center_mouse in range(3):   # we're going to do PCA three times, each time centered on one mouse (rotating to mouse-eye-view and centering might be better...)\n",
        "    ctr = np.median(keypoints[:,center_mouse,:,:],axis=1)\n",
        "    ctr = np.repeat(np.expand_dims(ctr,axis=1),3,axis=1)\n",
        "    ctr = np.repeat(np.expand_dims(ctr,axis=2), 12, axis=2)\n",
        "    keypoints_centered = keypoints - ctr\n",
        "    keypoints_centered = keypoints_centered.reshape(keypoints_centered.shape[0], -1)\n",
        "\n",
        "    pca_train[start:end,:, center_mouse] = keypoints_centered\n",
        "  start = end"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBWzFRDGYmKA"
      },
      "source": [
        "Now we'll fit a scalar transform to each mouse-centered dataset and compute the principal axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BoVkdOtG7Vtw"
      },
      "outputs": [],
      "source": [
        "embed_size = 20\n",
        "scaler_store = []\n",
        "pca_store = []\n",
        "for m in range(3):\n",
        "  pca = PCA(n_components = embed_size)\n",
        "  scaler = StandardScaler(with_std=False)\n",
        "  scaler_store.append(scaler.fit(pca_train[:,:,m]))\n",
        "  pca_store.append(pca.fit(pca_train[:,:,m]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHfpyQFFYPJw"
      },
      "source": [
        "Finally, now that we've found our principal axes for each transform of the data (centering poses on each mouse), let's project all of our submission trajectories onto those axes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hZElukY275NM"
      },
      "outputs": [],
      "source": [
        "num_total_frames = np.sum([seq[\"keypoints\"].shape[0] for _, seq in submission_clips['sequences'].items()])\n",
        "embeddings_array = np.empty((num_total_frames, embed_size*3), dtype=np.float32)\n",
        "\n",
        "frame_number_map = {}\n",
        "start = 0\n",
        "for sequence_key in submission_clips['sequences']:\n",
        "  keypoints = fill_holes(submission_clips['sequences'][sequence_key][\"keypoints\"])\n",
        "  if keypoints.size == 0:\n",
        "    keypoints = submission_clips['sequences'][sequence_key][\"keypoints\"]\n",
        "  embeddings = np.empty((len(keypoints),embed_size*3), dtype=np.float32)\n",
        "\n",
        "  for center_mouse in range(3):   # now apply our three PCA transformations to the test data\n",
        "    ctr = np.median(keypoints[:,center_mouse,:,:],axis=1)\n",
        "    ctr = np.repeat(np.expand_dims(ctr,axis=1),3,axis=1)\n",
        "    ctr = np.repeat(np.expand_dims(ctr,axis=2), 12, axis=2)\n",
        "    keypoints_centered = keypoints - ctr\n",
        "    keypoints_centered = keypoints_centered.reshape(keypoints_centered.shape[0], -1)\n",
        "\n",
        "    x = scaler_store[center_mouse].transform(keypoints_centered)\n",
        "    embeddings[:,(center_mouse*embed_size):((center_mouse+1)*embed_size)] = pca_store[center_mouse].transform(x)\n",
        "\n",
        "  end = start + len(keypoints)\n",
        "  embeddings_array[start:end] = embeddings\n",
        "  frame_number_map[sequence_key] = (start, end)\n",
        "  start = end\n",
        "  \n",
        "assert end == num_total_frames\n",
        "submission_dict = {\"frame_number_map\": frame_number_map, \"embeddings\": embeddings_array}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9I3r677F-U0U"
      },
      "outputs": [],
      "source": [
        "# Input and Embeddings shape\n",
        "print(\"Input shape:\", submission_clips['sequences'][sequence_key][\"keypoints\"].shape)\n",
        "print(\"Embedding shape:\", embeddings.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZYfbeJIrNt9"
      },
      "source": [
        "# Validate the submission ‚úÖ\n",
        "The submssion should follow these constraints:\n",
        "\n",
        "1.   It should be a dictionary with keys frame_number_map and embeddings\n",
        "2.   frame_number_map should be have same keys as submission_data\n",
        "3.   Embeddings is an 2D numpy array of dtype float32 \n",
        "4.   The embedding size should't exceed 128\n",
        "5.   The frame number map matches the clip lengths\n",
        "\n",
        "You can use the helper function below to check these\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nl5FrGHcrLy4"
      },
      "outputs": [],
      "source": [
        "def validate_submission(submission, submission_clips):\n",
        "    if not isinstance(submission, dict):\n",
        "      print(\"Submission should be dict\")\n",
        "      return False\n",
        "\n",
        "    if 'frame_number_map' not in submission:\n",
        "      print(\"Frame number map missing\")\n",
        "      return False\n",
        "\n",
        "    if 'embeddings' not in submission:\n",
        "        print('Embeddings array missing')\n",
        "        return False\n",
        "    elif not isinstance(submission['embeddings'], np.ndarray):\n",
        "        print(\"Embeddings should be a numpy array\")\n",
        "        return False\n",
        "    elif not len(submission['embeddings'].shape) == 2:\n",
        "        print(\"Embeddings should be 2D array\")\n",
        "        return False\n",
        "    elif not submission['embeddings'].shape[1] <= 128:\n",
        "        print(\"Embeddings too large, max allowed is 128\")\n",
        "        return False\n",
        "    elif not isinstance(submission['embeddings'][0, 0], np.float32):\n",
        "        print(f\"Embeddings are not float32\")\n",
        "        return False\n",
        "\n",
        "    \n",
        "    total_clip_length = 0\n",
        "    for key in submission_clips['sequences']:\n",
        "        start, end = submission['frame_number_map'][key]\n",
        "        clip_length = submission_clips['sequences'][key]['keypoints'].shape[0]\n",
        "        total_clip_length += clip_length\n",
        "        if not end-start == clip_length:\n",
        "            print(f\"Frame number map for clip {key} doesn't match clip length\")\n",
        "            return False\n",
        "            \n",
        "    if not len(submission['embeddings']) == total_clip_length:\n",
        "        print(f\"Emebddings length doesn't match submission clips total length\")\n",
        "        return False\n",
        "\n",
        "    if not np.isfinite(submission['embeddings']).all():\n",
        "        print(f\"Emebddings contains NaN or infinity\")\n",
        "        return False\n",
        "\n",
        "    print(\"All checks passed\")\n",
        "    return True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_twyjQEyaUy"
      },
      "outputs": [],
      "source": [
        "validate_submission(submission_dict, submission_clips)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPfKXGb1vTRd"
      },
      "source": [
        "## Save the prediction as `npy` üì®"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LkuPd5AvTRd"
      },
      "outputs": [],
      "source": [
        "np.save(\"submission.npy\", submission_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEZqmoHJJl4j"
      },
      "source": [
        "## Submit to AIcrowd üöÄ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yaUu2j8tCdZ1"
      },
      "outputs": [],
      "source": [
        "%aicrowd submission create --description \"PCA-v2\" -c {aicrowd_challenge_name} -f submission.npy"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Copy of mabe2022_mouse_pca",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
